"""
Phase 3 Enhanced: Baseline vs CR å¯¹æ¯”å®éªŒ (n=30)
è¡¥å¼ºç‰ˆæœ¬ï¼š
1. æ‰©å±•æµ‹è¯•é›†ä» n=10 åˆ° n=30ï¼ˆä¸‰ç±»é—®é¢˜ï¼Œæ¯ç±»10ä¸ªï¼‰
2. å¢åŠ äººå·¥äºŒåˆ†ç±»æ­£ç¡®ç‡è¯„ä¼°ï¼ˆæ£€ç´¢æ­£ç¡®ã€ç­”æ¡ˆæ­£ç¡®ï¼‰
"""
import os
import sys
import json
import time
from pathlib import Path

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from dotenv import load_dotenv
sys.path.insert(0, str(Path(__file__).parents[1]))

from llama_index.core import (
    VectorStoreIndex, 
    Settings,
    QueryBundle
)
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.schema import NodeWithScore
import chromadb
import jieba
from typing import List

load_dotenv()

# ============================================================================
# æ‰©å±•æµ‹è¯•é—®é¢˜é›† (n=30)
# ä¸‰ç±»é—®é¢˜ï¼Œæ¯ç±»10ä¸ªï¼š
#   Aç±»ï¼šæ•°å€¼/å±æ€§æŸ¥è¯¢ï¼ˆéœ€è¦ç²¾ç¡®åŒ¹é…ï¼‰
#   Bç±»ï¼šå®ä½“/å…³ç³»æŸ¥è¯¢ï¼ˆéœ€è¦ç†è§£ä¸Šä¸‹æ–‡å…³è”ï¼‰
#   Cç±»ï¼šæµç¨‹/æ¡ä»¶æŸ¥è¯¢ï¼ˆéœ€è¦å®Œæ•´æ®µè½ï¼‰
# ============================================================================

TEST_QUERIES = [
    # ========== Aç±»ï¼šæ•°å€¼/å±æ€§æŸ¥è¯¢ (10ä¸ª) ==========
    {"id": "A01", "query": "æ¨å®¶æ¨ªæ°´åº“çš„æ±›é™æ°´ä½æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§", 
     "expected_answer": "298.50mæˆ–ç›¸è¿‘æ•°å€¼", "keywords": ["æ±›é™æ°´ä½", "298", "æ°´ä½"]},
    {"id": "A02", "query": "å¸¸åº„æ°´åº“çš„æ€»åº“å®¹æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "1740ä¸‡ç«‹æ–¹ç±³", "keywords": ["æ€»åº“å®¹", "1740", "ä¸‡"]},
    {"id": "A03", "query": "æ¨å®¶æ¨ªæ°´åº“çš„æ ¡æ ¸æ´ªæ°´ä½æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "304.80mæˆ–ç›¸è¿‘æ•°å€¼", "keywords": ["æ ¡æ ¸", "æ´ªæ°´ä½", "304"]},
    {"id": "A04", "query": "å¸¸åº„æ°´åº“çš„å…´åˆ©åº“å®¹æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "700ä¸‡ç«‹æ–¹ç±³å·¦å³", "keywords": ["å…´åˆ©åº“å®¹", "700", "ä¸‡"]},
    {"id": "A05", "query": "æ¨å®¶æ¨ªæ°´åº“å¤§åçš„åé¡¶é«˜ç¨‹æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "306må·¦å³", "keywords": ["åé¡¶", "é«˜ç¨‹", "306"]},
    {"id": "A06", "query": "å¸¸åº„æ°´åº“çš„è®¾è®¡æ´ªæ°´ä½æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "å…·ä½“æ•°å€¼", "keywords": ["è®¾è®¡", "æ´ªæ°´ä½"]},
    {"id": "A07", "query": "æ¨å®¶æ¨ªæ°´åº“æ§åˆ¶çš„æµåŸŸé¢ç§¯æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "å¹³æ–¹å…¬é‡Œæ•°å€¼", "keywords": ["æµåŸŸé¢ç§¯", "å¹³æ–¹å…¬é‡Œ", "km"]},
    {"id": "A08", "query": "å¸¸åº„æ°´åº“çš„æ­»åº“å®¹æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "ä¸‡ç«‹æ–¹ç±³æ•°å€¼", "keywords": ["æ­»åº“å®¹", "ä¸‡"]},
    {"id": "A09", "query": "æ¨å®¶æ¨ªæ°´åº“æº¢æ´ªé“çš„è®¾è®¡æµé‡æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "ç«‹æ–¹ç±³æ¯ç§’", "keywords": ["æº¢æ´ªé“", "æµé‡", "mÂ³/s"]},
    {"id": "A10", "query": "å¸¸åº„æ°´åº“å¤§åçš„åé•¿æ˜¯å¤šå°‘ç±³ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "expected_answer": "ç±³æ•°å€¼", "keywords": ["åé•¿", "ç±³", "m"]},

    # ========== Bç±»ï¼šå®ä½“/å…³ç³»æŸ¥è¯¢ (10ä¸ª) ==========
    {"id": "B01", "query": "æ¨å®¶æ¨ªæ°´åº“çš„å¤§åå®‰å…¨è´£ä»»äººæ˜¯è°ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "å…·ä½“äººå", "keywords": ["è´£ä»»äºº", "å®‰å…¨", "è´Ÿè´£"]},
    {"id": "B02", "query": "å¸¸åº„æ°´åº“é˜²æ±›æŒ‡æŒ¥éƒ¨çš„æŒ‡æŒ¥é•¿æ˜¯è°ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "å‰¯å¸‚é•¿æˆ–å…·ä½“èŒåŠ¡", "keywords": ["æŒ‡æŒ¥é•¿", "é˜²æ±›", "æŒ‡æŒ¥éƒ¨"]},
    {"id": "B03", "query": "æ¨å®¶æ¨ªæ°´åº“ç”±å“ªä¸ªå•ä½ç®¡ç†ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "ç®¡ç†å¤„æˆ–ç®¡ç†å•ä½åç§°", "keywords": ["ç®¡ç†", "å•ä½", "å¤„"]},
    {"id": "B04", "query": "å¸¸åº„æ°´åº“çš„é˜²æ±›æŠ¢é™©æŠ€æœ¯è´Ÿè´£äººæ˜¯è°ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "å…·ä½“äººåæˆ–èŒåŠ¡", "keywords": ["æŠ€æœ¯", "è´Ÿè´£", "æŠ¢é™©"]},
    {"id": "B05", "query": "æ¨å®¶æ¨ªæ°´åº“ä½äºå“ªæ¡æ²³æµä¸Šï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "æ²³æµåç§°", "keywords": ["æ²³æµ", "ä½äº", "æ²³"]},
    {"id": "B06", "query": "å¸¸åº„æ°´åº“ä¸‹æ¸¸ä¸»è¦ä¿æŠ¤å“ªäº›åŒºåŸŸï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "ä¿æŠ¤åŒºåŸŸåç§°", "keywords": ["ä¸‹æ¸¸", "ä¿æŠ¤", "åŒºåŸŸ"]},
    {"id": "B07", "query": "æ¨å®¶æ¨ªæ°´åº“çš„ä¸Šçº§ä¸»ç®¡éƒ¨é—¨æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "æ°´åˆ©å±€æˆ–ç›¸å…³éƒ¨é—¨", "keywords": ["ä¸»ç®¡", "éƒ¨é—¨", "ä¸Šçº§"]},
    {"id": "B08", "query": "å¸¸åº„æ°´åº“å»ºäºå“ªä¸€å¹´ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "å¹´ä»½", "keywords": ["å»º", "å¹´", "å»ºæˆ"]},
    {"id": "B09", "query": "è°è´Ÿè´£é˜²æ´ªæŒ‡æŒ¥éƒ¨çš„ç»Ÿä¸€è°ƒåº¦ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "è¡Œæ”¿é¦–é•¿æˆ–å…·ä½“èŒåŠ¡", "keywords": ["è°ƒåº¦", "ç»Ÿä¸€", "è´Ÿè´£"]},
    {"id": "B10", "query": "é˜²æ±›ç‰©èµ„ç”±å“ªä¸ªéƒ¨é—¨è´Ÿè´£å‚¨å¤‡ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "expected_answer": "éƒ¨é—¨åç§°", "keywords": ["ç‰©èµ„", "å‚¨å¤‡", "éƒ¨é—¨"]},

    # ========== Cç±»ï¼šæµç¨‹/æ¡ä»¶æŸ¥è¯¢ (10ä¸ª) ==========
    {"id": "C01", "query": "ä»€ä¹ˆæƒ…å†µä¸‹éœ€è¦å¯åŠ¨IIIçº§åº”æ€¥å“åº”ï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "æ°´ä½æˆ–é›¨é‡æ¡ä»¶", "keywords": ["IIIçº§", "å“åº”", "å¯åŠ¨"]},
    {"id": "C02", "query": "æ°´åº“æ°´ä½è¾¾åˆ°å¤šå°‘æ—¶éœ€è¦å¼€å§‹æ³„æ´ªï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "æ°´ä½æ•°å€¼å’Œæ¡ä»¶", "keywords": ["æ³„æ´ª", "æ°´ä½", "å¼€å§‹"]},
    {"id": "C03", "query": "é˜²æ´ªæŠ¢é™©ç‰©èµ„å‚¨å¤‡åŒ…æ‹¬å“ªäº›ä¸œè¥¿ï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "ç‰©èµ„æ¸…å•", "keywords": ["ç‰©èµ„", "å‚¨å¤‡", "åŒ…æ‹¬"]},
    {"id": "C04", "query": "é˜²æ±›æŠ¢é™©é˜Ÿä¼ç”±å“ªäº›éƒ¨é—¨ç»„æˆï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "éƒ¨é—¨åˆ—è¡¨", "keywords": ["é˜Ÿä¼", "ç»„æˆ", "éƒ¨é—¨"]},
    {"id": "C05", "query": "å ¤é˜²å·¡æŸ¥çš„å…·ä½“æ­¥éª¤æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "å·¡æŸ¥æ­¥éª¤æè¿°", "keywords": ["å·¡æŸ¥", "æ­¥éª¤", "æ£€æŸ¥"]},
    {"id": "C06", "query": "å‘ç°é™©æƒ…ååº”è¯¥å¦‚ä½•æŠ¥å‘Šï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "æŠ¥å‘Šæµç¨‹", "keywords": ["é™©æƒ…", "æŠ¥å‘Š", "ä¸ŠæŠ¥"]},
    {"id": "C07", "query": "æ´ªæ°´é¢„è­¦ä¿¡å·æœ‰å“ªå‡ ä¸ªç­‰çº§ï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "ç­‰çº§åˆ’åˆ†", "keywords": ["é¢„è­¦", "ç­‰çº§", "ä¿¡å·"]},
    {"id": "C08", "query": "ç¾¤ä¼—è½¬ç§»å®‰ç½®çš„ç¨‹åºæ˜¯ä»€ä¹ˆï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "è½¬ç§»ç¨‹åº", "keywords": ["è½¬ç§»", "å®‰ç½®", "ç¾¤ä¼—"]},
    {"id": "C09", "query": "æ°´åº“å¤§åå‡ºç°è£‚ç¼åº”å¦‚ä½•å¤„ç†ï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "å¤„ç†æªæ–½", "keywords": ["è£‚ç¼", "å¤„ç†", "æªæ–½"]},
    {"id": "C10", "query": "é˜²æ±›å€¼ç­åˆ¶åº¦çš„å…·ä½“è¦æ±‚æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "expected_answer": "å€¼ç­è¦æ±‚", "keywords": ["å€¼ç­", "åˆ¶åº¦", "è¦æ±‚"]},
]

def chinese_tokenizer(text):
    """ä¸­æ–‡åˆ†è¯å™¨"""
    return list(jieba.cut_for_search(text))

class HybridRetriever(BaseRetriever):
    """æ··åˆæ£€ç´¢å™¨ï¼ˆå‘é‡+BM25ï¼‰"""
    def __init__(self, vector_retriever, bm25_retriever):
        self.vector_retriever = vector_retriever
        self.bm25_retriever = bm25_retriever
        super().__init__()

    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
        vector_results = self.vector_retriever.retrieve(query_bundle) if self.vector_retriever else []
        bm25_results = self.bm25_retriever.retrieve(query_bundle) if self.bm25_retriever else []
        
        all_nodes = {}
        for node in vector_results + bm25_results:
            if node.node_id not in all_nodes:
                all_nodes[node.node_id] = node
            else:
                if node.score and node.score > all_nodes[node.node_id].score:
                    all_nodes[node.node_id] = node
        
        sorted_nodes = sorted(all_nodes.values(), key=lambda x: x.score if x.score else 0, reverse=True)
        return sorted_nodes[:10]

def init_retriever(vector_db_path, bm25_path, collection_name, name=""):
    """åˆå§‹åŒ–æ£€ç´¢å™¨"""
    print(f"ğŸ”¹ {name}: åŠ è½½æ•°æ®åº“...")
    
    embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-zh-v1.5", device="cpu")
    
    if not os.path.exists(vector_db_path):
        print(f"   âŒ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨: {vector_db_path}")
        return None
    
    db = chromadb.PersistentClient(path=vector_db_path)
    try:
        chroma_collection = db.get_collection(collection_name)
        print(f"   âœ“ å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ (æ–‡æ¡£æ•°: {chroma_collection.count()})")
    except Exception as e:
        print(f"   âŒ åŠ è½½Collectionå¤±è´¥: {e}")
        return None
    
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    vector_index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)
    vector_retriever = vector_index.as_retriever(similarity_top_k=5)
    
    bm25_retriever = None
    if os.path.exists(bm25_path):
        try:
            bm25_retriever = BM25Retriever.from_persist_dir(bm25_path)
            bm25_retriever._similarity_top_k = 5
            print(f"   âœ“ BM25ç´¢å¼•åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"   âš ï¸ BM25åŠ è½½å¤±è´¥: {e}")
    
    return HybridRetriever(vector_retriever, bm25_retriever)

def evaluate_retrieval(top_text, keywords):
    """
    äººå·¥è¯„ä¼°è¾…åŠ©ï¼šæ£€æŸ¥æ£€ç´¢ç»“æœæ˜¯å¦åŒ…å«å…³é”®è¯
    è¿”å›ï¼šå‘½ä¸­çš„å…³é”®è¯æ•°é‡ / æ€»å…³é”®è¯æ•°é‡
    """
    hit_count = sum(1 for kw in keywords if kw in top_text)
    return hit_count / len(keywords) if keywords else 0

def run_experiment(name, retriever, queries):
    """è¿è¡Œå•ç»„å®éªŒ"""
    print(f"\n{'='*70}")
    print(f"å®éªŒ: {name} (n={len(queries)})")
    print(f"{'='*70}\n")
    
    if not retriever:
        print(f"âŒ {name} æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥")
        return None
    
    results = []
    category_stats = {}
    
    for item in queries:
        query = item["query"]
        qid = item["id"]
        category = item["category"]
        keywords = item.get("keywords", [])
        
        print(f"ğŸ” [{qid}] {query}")
        
        try:
            start = time.time()
            nodes = retriever.retrieve(QueryBundle(query))
            elapsed = time.time() - start
            
            if nodes and len(nodes) > 0:
                top_text = nodes[0].text[:500].replace('\n', ' ')
                top_score = nodes[0].score if nodes[0].score else 0
                results_count = len(nodes)
                
                # å…³é”®è¯å‘½ä¸­ç‡ï¼ˆè¾…åŠ©äººå·¥è¯„ä¼°ï¼‰
                keyword_hit_rate = evaluate_retrieval(top_text, keywords)
                # ç®€åŒ–åˆ¤æ–­ï¼šå‘½ä¸­ç‡>=50%è®¤ä¸ºæ£€ç´¢æ­£ç¡®
                retrieval_correct = keyword_hit_rate >= 0.5
            else:
                top_text = "æ— ç»“æœ"
                top_score = 0
                results_count = 0
                keyword_hit_rate = 0
                retrieval_correct = False
            
            result = {
                "id": qid,
                "query": query,
                "category": category,
                "time": elapsed,
                "top_1_text": top_text,
                "top_1_score": top_score,
                "results_count": results_count,
                "keyword_hit_rate": keyword_hit_rate,
                "retrieval_correct": retrieval_correct,  # æ£€ç´¢æ˜¯å¦æ­£ç¡®ï¼ˆåŸºäºå…³é”®è¯ï¼‰
                "answer_correct": None  # é¢„ç•™ï¼šäººå·¥æ ‡æ³¨ç­”æ¡ˆæ˜¯å¦æ­£ç¡®
            }
            results.append(result)
            
            # åˆ†ç±»ç»Ÿè®¡
            if category not in category_stats:
                category_stats[category] = {"total": 0, "correct": 0, "scores": []}
            category_stats[category]["total"] += 1
            category_stats[category]["scores"].append(top_score)
            if retrieval_correct:
                category_stats[category]["correct"] += 1
            
            mark = "âœ“" if retrieval_correct else "âœ—"
            print(f"   â±ï¸ {elapsed:.2f}s | å¾—åˆ†: {top_score:.3f} | å…³é”®è¯å‘½ä¸­: {keyword_hit_rate:.0%} {mark}")
            print(f"   ğŸ“„ {top_text[:80]}...\n")
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}\n")
            results.append({
                "id": qid,
                "query": query,
                "category": category,
                "error": str(e)
            })
    
    # æ‰“å°åˆ†ç±»ç»Ÿè®¡
    print(f"\n{'='*70}")
    print(f"{name} - åˆ†ç±»ç»Ÿè®¡")
    print(f"{'='*70}")
    for cat, stats in category_stats.items():
        avg_score = sum(stats["scores"]) / len(stats["scores"]) if stats["scores"] else 0
        acc = stats["correct"] / stats["total"] if stats["total"] > 0 else 0
        print(f"  {cat}: å‡†ç¡®ç‡ {acc:.0%} ({stats['correct']}/{stats['total']}), å¹³å‡å¾—åˆ† {avg_score:.3f}")
    
    return results

def generate_report(baseline_results, cr_results, queries):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    report_path = Path("results/phase3_enhanced_report.md")
    report_path.parent.mkdir(exist_ok=True)
    
    md = "# Phase 3 Enhanced: Baseline vs CR å¯¹æ¯”å®éªŒæŠ¥å‘Š\n\n"
    md += f"**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
    md += f"**æµ‹è¯•é—®é¢˜æ•°**: n={len(queries)}\n\n"
    
    md += "## å®éªŒé…ç½®\n\n"
    md += "| å®éªŒç»„ | è¯´æ˜ |\n"
    md += "|--------|------|\n"
    md += "| **Baseline** | åŸå§‹æ–‡æ¡£åˆ†å—ç›´æ¥æ£€ç´¢ï¼ˆå‘é‡+BM25æ··åˆï¼‰ |\n"
    md += "| **CR Enhanced** | ä¸Šä¸‹æ–‡å¢å¼ºæ£€ç´¢ï¼ˆæ¯ä¸ªåˆ†å—å¢åŠ äº†LLMç”Ÿæˆçš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼‰ |\n\n"
    
    md += "## é—®é¢˜åˆ†ç±»è¯´æ˜\n\n"
    md += "| ç±»åˆ« | æ•°é‡ | è¯´æ˜ |\n"
    md += "|------|------|------|\n"
    md += "| A-æ•°å€¼å±æ€§ | 10 | éœ€è¦ç²¾ç¡®åŒ¹é…æ•°å€¼çš„æŸ¥è¯¢ï¼ˆå¦‚æ°´ä½ã€åº“å®¹ï¼‰ |\n"
    md += "| B-å®ä½“å…³ç³» | 10 | éœ€è¦ç†è§£å®ä½“å…³è”çš„æŸ¥è¯¢ï¼ˆå¦‚è´£ä»»äººã€ç®¡ç†å•ä½ï¼‰ |\n"
    md += "| C-æµç¨‹æ¡ä»¶ | 10 | éœ€è¦å®Œæ•´æ®µè½çš„æŸ¥è¯¢ï¼ˆå¦‚æ“ä½œæ­¥éª¤ã€æ¡ä»¶è§¦å‘ï¼‰ |\n\n"
    
    # åˆ†ç±»æ±‡æ€»
    md += "## åˆ†ç±»æ±‡æ€»ç»“æœ\n\n"
    md += "| ç±»åˆ« | Baselineå‡†ç¡®ç‡ | CRå‡†ç¡®ç‡ | Baselineå¾—åˆ† | CRå¾—åˆ† | å·®å¼‚ |\n"
    md += "|------|----------------|----------|--------------|--------|------|\n"
    
    categories = ["A-æ•°å€¼å±æ€§", "B-å®ä½“å…³ç³»", "C-æµç¨‹æ¡ä»¶"]
    
    for cat in categories:
        b_items = [r for r in baseline_results if r.get("category") == cat and "error" not in r]
        c_items = [r for r in cr_results if r.get("category") == cat and "error" not in r]
        
        b_correct = sum(1 for r in b_items if r.get("retrieval_correct"))
        c_correct = sum(1 for r in c_items if r.get("retrieval_correct"))
        b_acc = b_correct / len(b_items) if b_items else 0
        c_acc = c_correct / len(c_items) if c_items else 0
        
        b_score = sum(r.get("top_1_score", 0) for r in b_items) / len(b_items) if b_items else 0
        c_score = sum(r.get("top_1_score", 0) for r in c_items) / len(c_items) if c_items else 0
        
        diff = c_score - b_score
        indicator = "ğŸ“ˆ" if diff > 0.01 else ("ğŸ“‰" if diff < -0.01 else "â¡ï¸")
        
        md += f"| {cat} | {b_acc:.0%} ({b_correct}/{len(b_items)}) | {c_acc:.0%} ({c_correct}/{len(c_items)}) | {b_score:.3f} | {c_score:.3f} | {diff:+.3f} {indicator} |\n"
    
    # æ€»ä½“ç»Ÿè®¡
    md += "\n## æ€»ä½“ç»Ÿè®¡\n\n"
    
    if baseline_results and cr_results:
        b_scores = [r.get("top_1_score", 0) for r in baseline_results if "error" not in r]
        c_scores = [r.get("top_1_score", 0) for r in cr_results if "error" not in r]
        b_correct = sum(1 for r in baseline_results if r.get("retrieval_correct"))
        c_correct = sum(1 for r in cr_results if r.get("retrieval_correct"))
        
        avg_b_score = sum(b_scores) / len(b_scores) if b_scores else 0
        avg_c_score = sum(c_scores) / len(c_scores) if c_scores else 0
        b_acc = b_correct / len(baseline_results)
        c_acc = c_correct / len(cr_results)
        
        md += "| æŒ‡æ ‡ | Baseline | CR Enhanced | å·®å¼‚ |\n"
        md += "|------|----------|-------------|------|\n"
        md += f"| å¹³å‡ç›¸ä¼¼åº¦å¾—åˆ† | {avg_b_score:.4f} | {avg_c_score:.4f} | {avg_c_score - avg_b_score:+.4f} |\n"
        md += f"| æ£€ç´¢æ­£ç¡®ç‡ | {b_acc:.1%} ({b_correct}/{len(baseline_results)}) | {c_acc:.1%} ({c_correct}/{len(cr_results)}) | {c_acc - b_acc:+.1%} |\n"
        
        # ç»Ÿè®¡æ£€éªŒ
        import math
        n = len(b_scores)
        diffs = [c - b for b, c in zip(b_scores, c_scores)]
        mean_diff = sum(diffs) / n
        variance = sum((d - mean_diff)**2 for d in diffs) / (n - 1)
        std_diff = math.sqrt(variance)
        se = std_diff / math.sqrt(n)
        t_stat = mean_diff / se if se > 0 else 0
        
        md += f"\n### ç»Ÿè®¡æ£€éªŒ (é…å¯¹tæ£€éªŒ)\n\n"
        md += f"- æ ·æœ¬é‡ n = {n}\n"
        md += f"- å¹³å‡å·®å¼‚ = {mean_diff:+.4f}\n"
        md += f"- t ç»Ÿè®¡é‡ = {t_stat:.3f}\n"
        md += f"- ä¸´ç•Œå€¼ (Î±=0.05, df={n-1}) â‰ˆ 2.045\n"
        
        if abs(t_stat) > 2.045:
            md += f"- **ç»“è®º**: å·®å¼‚æ˜¾è‘— (p < 0.05) âœ…\n"
        else:
            md += f"- **ç»“è®º**: å·®å¼‚ä¸æ˜¾è‘— (p > 0.05) âš ï¸\n"
        
        # ç¬¦å·æ£€éªŒ
        pos = sum(1 for d in diffs if d > 0)
        neg = sum(1 for d in diffs if d < 0)
        tie = sum(1 for d in diffs if d == 0)
        md += f"\n### ç¬¦å·æ£€éªŒ\n\n"
        md += f"- CR > Baseline: {pos} æ¬¡\n"
        md += f"- CR < Baseline: {neg} æ¬¡\n"
        md += f"- CR = Baseline: {tie} æ¬¡\n"
    
    # é€é¢˜è¯¦æƒ…ï¼ˆç®€åŒ–ç‰ˆï¼‰
    md += "\n## é€é¢˜ç»“æœæ¦‚è§ˆ\n\n"
    md += "| ID | é—®é¢˜ | ç±»åˆ« | Baseline | CR | Winner |\n"
    md += "|----|----|------|----------|-----|--------|\n"
    
    for i, item in enumerate(queries):
        qid = item["id"]
        query_short = item["query"][:20] + "..." if len(item["query"]) > 20 else item["query"]
        cat = item["category"].split("-")[0]
        
        b_result = baseline_results[i] if baseline_results and i < len(baseline_results) else {}
        c_result = cr_results[i] if cr_results and i < len(cr_results) else {}
        
        b_score = b_result.get("top_1_score", 0)
        c_score = c_result.get("top_1_score", 0)
        b_mark = "âœ“" if b_result.get("retrieval_correct") else "âœ—"
        c_mark = "âœ“" if c_result.get("retrieval_correct") else "âœ—"
        
        if c_score > b_score + 0.01:
            winner = "CR"
        elif b_score > c_score + 0.01:
            winner = "Baseline"
        else:
            winner = "å¹³å±€"
        
        md += f"| {qid} | {query_short} | {cat} | {b_score:.3f} {b_mark} | {c_score:.3f} {c_mark} | {winner} |\n"
    
    # ç»“è®º
    md += "\n## ç»“è®º\n\n"
    if avg_c_score > avg_b_score:
        improvement = ((avg_c_score - avg_b_score) / avg_b_score * 100) if avg_b_score > 0 else 0
        md += f"1. **CR Enhanced ç›¸æ¯” Baseline å¹³å‡ç›¸ä¼¼åº¦æå‡äº† {improvement:.1f}%**\n"
    else:
        md += f"1. **CR Enhanced ä¸ Baseline æ•ˆæœç›¸è¿‘æˆ–ç•¥æœ‰ä¸‹é™**\n"
    
    md += f"2. **æ£€ç´¢æ­£ç¡®ç‡**: Baseline {b_acc:.1%} vs CR {c_acc:.1%}\n"
    md += f"3. **ç¬¦å·æ£€éªŒ**: CRåœ¨ {pos}/{n} ä¸ªé—®é¢˜ä¸Šè¡¨ç°æ›´å¥½\n"
    
    report_path.write_text(md, encoding='utf-8')
    print(f"\nğŸ“Š å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # ä¿å­˜ JSON æ ¼å¼ï¼ˆåŒ…å«å®Œæ•´æ•°æ®ä¾›äººå·¥æ ‡æ³¨ï¼‰
    json_path = Path("results/phase3_enhanced_data.json")
    json_data = {
        "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
        "config": {
            "n_questions": len(queries),
            "categories": ["A-æ•°å€¼å±æ€§", "B-å®ä½“å…³ç³»", "C-æµç¨‹æ¡ä»¶"]
        },
        "summary": {
            "baseline_avg_score": avg_b_score,
            "cr_avg_score": avg_c_score,
            "baseline_accuracy": b_acc,
            "cr_accuracy": c_acc,
            "t_statistic": t_stat,
            "sign_test": {"cr_wins": pos, "baseline_wins": neg, "ties": tie}
        },
        "baseline": baseline_results,
        "cr_enhanced": cr_results
    }
    json_path.write_text(json.dumps(json_data, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"ğŸ“Š JSONæ•°æ®å·²ä¿å­˜: {json_path}")
    
    return json_data["summary"]

def main():
    print("="*80)
    print("  Phase 3 Enhanced: Baseline vs CR å¯¹æ¯”å®éªŒ (n=30)")
    print("="*80)
    
    # æ•°æ®åº“è·¯å¾„é…ç½®
    BASELINE_VECTOR_DB = "./src/db/flood_prevention_db_baseline_vectordb"
    BASELINE_BM25_DB = "./src/db/flood_prevention_db_baseline_bm25"
    CR_VECTOR_DB = "./src/db/flood_prevention_db_cr_vectordb"
    CR_BM25_DB = "./src/db/flood_prevention_db_cr_bm25"
    COLLECTION_NAME = "flood_prevention_collection"
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    print("\n[1/3] åˆå§‹åŒ–æ£€ç´¢å™¨...")
    baseline_retriever = init_retriever(BASELINE_VECTOR_DB, BASELINE_BM25_DB, COLLECTION_NAME, "Baseline")
    cr_retriever = init_retriever(CR_VECTOR_DB, CR_BM25_DB, COLLECTION_NAME, "CR Enhanced")
    
    # è¿è¡Œå®éªŒ
    print("\n[2/3] è¿è¡Œå¯¹æ¯”å®éªŒ...")
    baseline_results = run_experiment("Baseline", baseline_retriever, TEST_QUERIES)
    cr_results = run_experiment("CR Enhanced", cr_retriever, TEST_QUERIES)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n[3/3] ç”ŸæˆæŠ¥å‘Š...")
    if baseline_results and cr_results:
        summary = generate_report(baseline_results, cr_results, TEST_QUERIES)
        
        print("\n" + "="*80)
        print("  å®éªŒå®Œæˆ - æ±‡æ€»ç»“æœ")
        print("="*80)
        print(f"  æ ·æœ¬é‡: n={len(TEST_QUERIES)}")
        print(f"  Baseline å¹³å‡å¾—åˆ†: {summary['baseline_avg_score']:.4f}")
        print(f"  CR å¹³å‡å¾—åˆ†: {summary['cr_avg_score']:.4f}")
        print(f"  Baseline æ£€ç´¢æ­£ç¡®ç‡: {summary['baseline_accuracy']:.1%}")
        print(f"  CR æ£€ç´¢æ­£ç¡®ç‡: {summary['cr_accuracy']:.1%}")
        print(f"  t ç»Ÿè®¡é‡: {summary['t_statistic']:.3f}")
        print(f"  ç¬¦å·æ£€éªŒ: CRèƒœ {summary['sign_test']['cr_wins']}, Baselineèƒœ {summary['sign_test']['baseline_wins']}, å¹³å±€ {summary['sign_test']['ties']}")
    
    print("\n" + "="*80)
    print("âœ… Phase 3 Enhanced å®éªŒå®Œæˆï¼")
    print("="*80)

if __name__ == "__main__":
    main()
