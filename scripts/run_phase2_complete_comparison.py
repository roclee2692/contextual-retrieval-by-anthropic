"""
Phase 2 å®Œæ•´ä¸‰ç»„å¯¹æ¯”å®éªŒ
å¯¹æ¯” Baseline (æ— ä¸Šä¸‹æ–‡) vs CR (æœ‰ä¸Šä¸‹æ–‡) vs KG (çŸ¥è¯†å›¾è°±)
"""
import os
import sys
import json
import time
from pathlib import Path

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from dotenv import load_dotenv
sys.path.insert(0, str(Path(__file__).parents[1]))

from llama_index.core import VectorStoreIndex, QueryBundle
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.schema import NodeWithScore
import chromadb
import jieba
from typing import List

load_dotenv()

# æµ‹è¯•é—®é¢˜é›†
TEST_QUERIES = [
    {"query": "æ¨å®¶æ¨ªæ°´åº“çš„æ±›é™æ°´ä½æ˜¯å¤šå°‘ï¼Ÿ", "category": "æ•°å€¼æŸ¥è¯¢"},
    {"query": "é˜²æ´ªé¢„æ¡ˆä¸­çš„åº”æ€¥é¢„æ¡ˆç­‰çº§æœ‰å“ªäº›ï¼Ÿ", "category": "åˆ†çº§æŸ¥è¯¢"},
    {"query": "å ¤é˜²å·¡æŸ¥çš„æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "æ ‡å‡†è§„èŒƒ"},
    {"query": "æ±›æœŸè°ƒåº¦çš„è§„åˆ™æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "è§„åˆ™æµç¨‹"},
    {"query": "é˜²æ´ªæŠ¢é™©æœ‰å“ªäº›æªæ–½ï¼Ÿ", "category": "æªæ–½æ¸…å•"},
    {"query": "æ°´ä½è¶…è¿‡å¤šå°‘éœ€è¦å¯åŠ¨é¢„æ¡ˆï¼Ÿ", "category": "è§¦å‘æ¡ä»¶"},
    {"query": "è°è´Ÿè´£é˜²æ´ªæŒ‡æŒ¥è°ƒåº¦ï¼Ÿ", "category": "è´£ä»»äººæŸ¥è¯¢"},
    {"query": "æ°´åº“å¤§åå‡ºç°é™©æƒ…æ—¶åº”è¯¥è”ç³»è°ï¼Ÿ", "category": "å¤šè·³æ¨ç†"},
]

def chinese_tokenizer(text):
    return list(jieba.cut_for_search(text))

class HybridRetriever(BaseRetriever):
    def __init__(self, vector_retriever, bm25_retriever):
        self.vector_retriever = vector_retriever
        self.bm25_retriever = bm25_retriever
        super().__init__()

    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
        vector_results = self.vector_retriever.retrieve(query_bundle) if self.vector_retriever else []
        bm25_results = self.bm25_retriever.retrieve(query_bundle) if self.bm25_retriever else []
        
        all_nodes = {node.node_id: node for node in vector_results + bm25_results}
        sorted_nodes = sorted(all_nodes.values(), key=lambda x: x.score if x.score else 0, reverse=True)
        return sorted_nodes[:10]

def init_retriever(db_path, bm25_path, collection_name):
    """åˆå§‹åŒ–æ£€ç´¢å™¨"""
    embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-zh-v1.5", device="cpu")
    
    if not os.path.exists(db_path):
        return None
    
    db = chromadb.PersistentClient(path=db_path)
    try:
        chroma_collection = db.get_collection(collection_name)
    except:
        return None
    
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    vector_index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)
    vector_retriever = vector_index.as_retriever(similarity_top_k=10)
    
    bm25_retriever = None
    if os.path.exists(bm25_path):
        bm25_retriever = BM25Retriever.from_persist_dir(bm25_path)
        bm25_retriever._similarity_top_k = 10
    
    return HybridRetriever(vector_retriever, bm25_retriever)

def run_experiment(experiment_name, db_path, bm25_path, collection_name):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    print(f"\n{'='*60}")
    print(f"è¿è¡Œå®éªŒ: {experiment_name}")
    print(f"{'='*60}\n")
    
    retriever = init_retriever(db_path, bm25_path, collection_name)
    if not retriever:
        print(f"âŒ æ— æ³•åˆå§‹åŒ–æ£€ç´¢å™¨ï¼Œè¯·æ£€æŸ¥æ•°æ®åº“è·¯å¾„")
        return None
    
    results = []
    for item in TEST_QUERIES:
        query = item["query"]
        print(f"æŸ¥è¯¢: {query}")
        
        try:
            start = time.time()
            nodes = retriever.retrieve(QueryBundle(query))
            elapsed = time.time() - start
            
            top_result = {
                "query": query,
                "category": item["category"],
                "time": elapsed,
                "top_1_preview": nodes[0].text[:200] if nodes else "æ— ç»“æœ",
                "top_1_score": nodes[0].score if nodes else 0,
                "results_count": len(nodes)
            }
            results.append(top_result)
            print(f"  âœ… è€—æ—¶: {elapsed:.2f}s, Top-1 Score: {top_result['top_1_score']:.3f}")
            print(f"  é¢„è§ˆ: {top_result['top_1_preview'][:100]}...")
        except Exception as e:
            print(f"  âŒ é”™è¯¯: {e}")
            results.append({
                "query": query,
                "category": item["category"],
                "error": str(e)
            })
    
    return results

def main():
    # å®éªŒé…ç½®
    experiments = {
        "Baseline": {
            "db_path": "./src/db/flood_prevention_db_baseline_vectordb",
            "bm25_path": "./src/db/flood_prevention_db_baseline_bm25",
            "collection": "flood_prevention_collection"
        },
        "CR_Enhanced": {
            "db_path": "./src/db/flood_prevention_db_vectordb",
            "bm25_path": "./src/db/flood_prevention_db_bm25",
            "collection": "flood_prevention_collection"
        }
    }
    
    all_results = {}
    
    for exp_name, config in experiments.items():
        results = run_experiment(exp_name, config["db_path"], config["bm25_path"], config["collection"])
        if results:
            all_results[exp_name] = results
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    if len(all_results) >= 2:
        generate_comparison_report(all_results)
    
    print("\nâœ… å®éªŒå®Œæˆï¼")

def generate_comparison_report(all_results):
    """ç”Ÿæˆ Markdown å¯¹æ¯”æŠ¥å‘Š"""
    report_path = Path("results/phase2_complete_comparison.md")
    
    md = "# Phase 2: ä¸‰ç»„å®éªŒå®Œæ•´å¯¹æ¯”æŠ¥å‘Š\n\n"
    md += "## å®éªŒé…ç½®\n\n"
    md += "| å®éªŒ | è¯´æ˜ |\n"
    md += "|---|---|\n"
    md += "| Baseline | çº¯å‘é‡+BM25ï¼Œæ— ä¸Šä¸‹æ–‡å¢å¼º |\n"
    md += "| CR Enhanced | LLMç”Ÿæˆä¸Šä¸‹æ–‡å‰ç¼€åæ£€ç´¢ |\n"
    md += "| Knowledge Graph | çŸ¥è¯†å›¾è°±æ¨ç†ï¼ˆå¾…è¡¥å……ï¼‰|\n\n"
    
    md += "## é€é¢˜å¯¹æ¯”\n\n"
    
    # è·å–æ‰€æœ‰æŸ¥è¯¢
    queries = [item["query"] for item in all_results[list(all_results.keys())[0]]]
    
    for i, query in enumerate(queries):
        md += f"### Q{i+1}: {query}\n\n"
        md += "| å®éªŒ | Top-1 é¢„è§ˆ | å¾—åˆ† | è€—æ—¶(s) |\n"
        md += "|---|---|---|---|\n"
        
        for exp_name, results in all_results.items():
            item = results[i]
            preview = item.get("top_1_preview", "N/A")[:100].replace('|', '\\|')
            score = item.get("top_1_score", 0)
            elapsed = item.get("time", 0)
            md += f"| {exp_name} | {preview}... | {score:.3f} | {elapsed:.2f} |\n"
        
        md += "\n"
    
    report_path.write_text(md, encoding='utf-8')
    print(f"\nğŸ“Š å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

if __name__ == "__main__":
    main()
