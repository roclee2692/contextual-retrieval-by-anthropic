"""
çº¯æ£€ç´¢æµ‹è¯• - ä¸ä½¿ç”¨LLMï¼Œç›´æ¥æŸ¥çœ‹æ£€ç´¢ç»“æœ
ç”¨äºè¯Šæ–­æ£€ç´¢è´¨é‡é—®é¢˜
"""
import os
import chromadb
from dotenv import load_dotenv
from llama_index.core import VectorStoreIndex
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core import Settings
import jieba

load_dotenv()

# ä¸­æ–‡åˆ†è¯å™¨
def chinese_tokenizer(text):
    """å¢å¼ºå‹ä¸­æ–‡åˆ†è¯å™¨"""
    tokens = list(jieba.cut_for_search(text))
    enhanced_tokens = []
    for token in tokens:
        enhanced_tokens.append(token)
        if 'åŒ…' in token:
            enhanced_tokens.append('åŒ…')
            enhanced_tokens.append('åŒ…å­')
    return enhanced_tokens

print("=" * 80)
print("ğŸ” çº¯æ£€ç´¢æµ‹è¯•ï¼ˆæ— LLMï¼‰")
print("=" * 80)

# åŠ è½½é…ç½®
vector_db_path = "./src/db/canteen_db_vectordb"
bm25_db_path = "./src/db/canteen_db_bm25"
collection_name = "ncwu_canteen_collection"

# åˆå§‹åŒ– Embedding - ä½¿ç”¨ä¸­æ–‡æ¨¡å‹
print("\n1. åŠ è½½ Embedding æ¨¡å‹...")
embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5",  # ä¸­æ–‡æ¨¡å‹
    device="cpu"
)
Settings.embed_model = embed_model
print("âœ“ å®Œæˆ")

# åŠ è½½å‘é‡æ•°æ®åº“
print("\n2. åŠ è½½å‘é‡æ•°æ®åº“...")
vectordb_client = chromadb.PersistentClient(path=vector_db_path)
chroma_collection = vectordb_client.get_or_create_collection(collection_name)
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
vector_index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)
print("âœ“ å®Œæˆ")

# åŠ è½½ BM25
print("\n3. åŠ è½½ BM25 æ•°æ®åº“...")
bm25_retriever = BM25Retriever.from_persist_dir(bm25_db_path)
print("âœ“ å®Œæˆ")

# æµ‹è¯•é—®é¢˜
test_questions = [
    "ä¸€å·é¤å…æœ‰å“ªäº›çª—å£æˆ–æ¡£å£ï¼Ÿ",
    "äºŒå·é¤å…ä¸€æ¥¼æœ‰å“ªäº›æ¡£å£ï¼Ÿ",
    "å“ªäº›çª—å£æä¾›åŒ…å­ç±»é£Ÿå“ï¼Ÿ",
    "å¤©æ´¥åŒ…å­åœ¨å“ªä¸ªçª—å£ï¼Ÿ",
    "é¦™æ¸¯ä¹é¾™åŒ…å¤šå°‘é’±ï¼Ÿ",
]

print("\n" + "=" * 80)
print("å¼€å§‹æ£€ç´¢æµ‹è¯•")
print("=" * 80)

for i, query in enumerate(test_questions, 1):
    print(f"\n{'='*80}")
    print(f"é—®é¢˜ {i}: {query}")
    print('='*80)

    # å‘é‡æ£€ç´¢
    print("\nã€å‘é‡æ£€ç´¢ã€‘(Top 5)")
    print("-" * 80)
    vector_retriever = vector_index.as_retriever(similarity_top_k=5)
    vector_nodes = vector_retriever.retrieve(query)

    for j, node in enumerate(vector_nodes, 1):
        score = node.score if hasattr(node, 'score') else 0.0
        print(f"\nç»“æœ {j} (ç›¸ä¼¼åº¦: {score:.4f})")
        print(f"å†…å®¹: {node.text[:200]}...")

    # BM25æ£€ç´¢
    print(f"\n\nã€BM25æ£€ç´¢ã€‘(Top 5)")
    print("-" * 80)
    bm25_retriever.similarity_top_k = 5
    bm25_nodes = bm25_retriever.retrieve(query)

    for j, node in enumerate(bm25_nodes, 1):
        score = node.score if hasattr(node, 'score') else 0.0
        print(f"\nç»“æœ {j} (BM25åˆ†æ•°: {score:.4f})")
        print(f"å†…å®¹: {node.text[:200]}...")

    # æ··åˆç»“æœ
    print(f"\n\nã€æ··åˆå»é‡åã€‘")
    print("-" * 80)
    all_nodes = list({n.node.node_id: n for n in (vector_nodes + bm25_nodes)}.values())
    print(f"å‘é‡æ£€ç´¢: {len(vector_nodes)} ä¸ªç»“æœ")
    print(f"BM25æ£€ç´¢: {len(bm25_nodes)} ä¸ªç»“æœ")
    print(f"å»é‡å: {len(all_nodes)} ä¸ªå”¯ä¸€ç»“æœ")

print("\n" + "=" * 80)
print("æ£€ç´¢æµ‹è¯•å®Œæˆ")
print("=" * 80)

print("\nğŸ’¡ åˆ†æå»ºè®®:")
print("-" * 80)
print("1. æ£€æŸ¥å‘é‡æ£€ç´¢çš„ç›¸ä¼¼åº¦åˆ†æ•°æ˜¯å¦åˆç†ï¼ˆ0-1ä¹‹é—´ï¼‰")
print("2. æ£€æŸ¥BM25åˆ†æ•°æ˜¯å¦ä¸º0ï¼ˆå¦‚æœæ˜¯0è¯´æ˜æœ‰é—®é¢˜ï¼‰")
print("3. æ£€æŸ¥æ£€ç´¢åˆ°çš„å†…å®¹æ˜¯å¦ä¸é—®é¢˜ç›¸å…³")
print("4. å¦‚æœBM25å…¨æ˜¯0ï¼Œéœ€è¦é‡å»ºBM25ç´¢å¼•")
print("5. å¦‚æœå†…å®¹ä¸ç›¸å…³ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´chunk_sizeæˆ–ä½¿ç”¨ä¸­æ–‡embedding")

