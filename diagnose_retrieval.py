"""
è¯Šæ–­ CR v2 æ£€ç´¢é—®é¢˜
"""
import os
from dotenv import load_dotenv
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.ollama import Ollama
import chromadb
from llama_index.vector_stores.chroma import ChromaVectorStore

load_dotenv()

print("="*80)
print("è¯Šæ–­ CR v2 æ£€ç´¢é—®é¢˜")
print("="*80)

# 1. è¯»å– PDF æŸ¥çœ‹å†…å®¹
print("\n[1/4] è¯»å– PDF å†…å®¹...")
docs = SimpleDirectoryReader("./data").load_data()
print(f"âœ“ æ–‡æ¡£æ•°: {len(docs)}")
print(f"âœ“ æ€»å­—ç¬¦æ•°: {sum(len(d.text) for d in docs)}")

# æ£€æŸ¥å…³é”®å†…å®¹
full_text = docs[0].text if docs else ""
print(f"âœ“ åŒ…å«'ä¸€å·é¤å…': {'ä¸€å·é¤å…' in full_text}")
print(f"âœ“ åŒ…å«'åŒ…å­': {'åŒ…å­' in full_text}")
print(f"âœ“ åŒ…å«'42å·': {'42å·' in full_text or '42' in full_text}")

# æ˜¾ç¤ºå‰500å­—ç¬¦
print(f"\nå‰500å­—ç¬¦é¢„è§ˆï¼š")
print("-"*80)
print(full_text[:500])
print("-"*80)

# 2. æµ‹è¯• Embedding è´¨é‡
print("\n[2/4] æµ‹è¯• Embedding è´¨é‡...")

# ä½¿ç”¨ä¸­æ–‡ Embedding æ¨¡å‹
embed_model_cn = HuggingFaceEmbedding(
    model_name="BAAI/bge-base-zh-v1.5"  # ä¸­æ–‡æ¨¡å‹
)

embed_model_en = HuggingFaceEmbedding(
    model_name="BAAI/bge-base-en-v1.5"  # è‹±æ–‡æ¨¡å‹ï¼ˆå½“å‰ä½¿ç”¨ï¼‰
)

query = "ä¸€å·é¤å…æœ‰å“ªäº›çª—å£"
text_sample = "Context: Canteen=1 | Window=42 | ä¸€ã€é¦™æ¸¯ä¹é¾™åŒ…ï¼ˆ42å·æ¡£å£ï¼‰"

# è®¡ç®—ç›¸ä¼¼åº¦
query_emb_cn = embed_model_cn.get_query_embedding(query)
text_emb_cn = embed_model_cn.get_text_embedding(text_sample)
similarity_cn = sum(a*b for a,b in zip(query_emb_cn, text_emb_cn))

query_emb_en = embed_model_en.get_query_embedding(query)
text_emb_en = embed_model_en.get_text_embedding(text_sample)
similarity_en = sum(a*b for a,b in zip(query_emb_en, text_emb_en))

print(f"âœ“ ä¸­æ–‡æ¨¡å‹ç›¸ä¼¼åº¦: {similarity_cn:.4f}")
print(f"âœ“ è‹±æ–‡æ¨¡å‹ç›¸ä¼¼åº¦: {similarity_en:.4f}")
print(f"âœ“ å·®å¼‚: {abs(similarity_cn - similarity_en):.4f}")

if similarity_cn > similarity_en * 1.1:
    print("âš ï¸  ä¸­æ–‡æ¨¡å‹æ˜¾è‘—æ›´å¥½ï¼å»ºè®®åˆ‡æ¢åˆ°ä¸­æ–‡ Embedding")

# 3. æµ‹è¯•å½“å‰æ•°æ®åº“æ£€ç´¢
print("\n[3/4] æµ‹è¯•å½“å‰æ•°æ®åº“æ£€ç´¢...")

vectordb_client = chromadb.PersistentClient(path="./src/db/canteen_db_vectordb")
chroma_collection = vectordb_client.get_or_create_collection("ncwu_canteen_collection")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)

# ä½¿ç”¨å½“å‰çš„è‹±æ–‡æ¨¡å‹
Settings.embed_model = embed_model_en
vector_index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model_en)

# æµ‹è¯•æ£€ç´¢
retriever = vector_index.as_retriever(similarity_top_k=5)
nodes = retriever.retrieve(query)

print(f"âœ“ æ£€ç´¢åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹")
for i, node in enumerate(nodes, 1):
    print(f"\nèŠ‚ç‚¹ {i} (ç›¸ä¼¼åº¦: {node.score:.4f}):")
    print(f"å†…å®¹: {node.text[:200]}...")

# 4. æµ‹è¯•ä¸åŒçš„æ£€ç´¢å‚æ•°
print("\n[4/4] æµ‹è¯•ä¸åŒçš„ top_k å‚æ•°...")

for k in [3, 5, 10]:
    retriever_k = vector_index.as_retriever(similarity_top_k=k)
    nodes_k = retriever_k.retrieve(query)

    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³å†…å®¹
    has_relevant = any('ä¸€å·' in node.text or '42' in node.text for node in nodes_k)
    print(f"top_k={k}: æ£€ç´¢åˆ° {len(nodes_k)} ä¸ªèŠ‚ç‚¹, åŒ…å«ç›¸å…³å†…å®¹: {has_relevant}")

print("\n" + "="*80)
print("è¯Šæ–­å®Œæˆï¼")
print("="*80)

print("\nğŸ“Š å»ºè®®ï¼š")
print("1. å¦‚æœä¸­æ–‡æ¨¡å‹ç›¸ä¼¼åº¦æ›´é«˜ï¼Œåˆ‡æ¢åˆ° bge-base-zh-v1.5")
print("2. å¦‚æœ top_k=10 èƒ½æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œå¢å¤§æ£€ç´¢æ•°é‡")
print("3. å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œå¯èƒ½æ˜¯æ•°æ®åº“åˆ›å»ºæ—¶çš„é—®é¢˜")

