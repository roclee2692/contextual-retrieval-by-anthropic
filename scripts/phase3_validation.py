"""
Phase 3 éªŒè¯å®éªŒï¼šæ£€æŸ¥å®éªŒä¸€è‡´æ€§ & Case çº§åˆ«åˆ†æ
ç›®çš„ï¼š
1. ç»Ÿä¸€ top_k è®¾ç½®
2. æ‰“å° Baseline vs CR æ£€ç´¢æ–‡æœ¬å¯¹æ¯”
3. äººå·¥æŠ½æŸ¥éªŒè¯
"""
import os
import sys
import json
from pathlib import Path
from datetime import datetime

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from dotenv import load_dotenv
sys.path.insert(0, str(Path(__file__).parents[1]))

from llama_index.core import VectorStoreIndex, QueryBundle
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.schema import NodeWithScore
import chromadb
from typing import List
import numpy as np

load_dotenv()

# ============================================================================
# é…ç½®ï¼šç»Ÿä¸€ top_k
# ============================================================================
VECTOR_TOP_K = 10  # ç»Ÿä¸€å‘é‡æ£€ç´¢ top_k
BM25_TOP_K = 10    # ç»Ÿä¸€ BM25 æ£€ç´¢ top_k
FINAL_TOP_K = 3    # æœ€ç»ˆè¿”å› top_k

# ============================================================================
# æµ‹è¯•é—®é¢˜ï¼ˆé€‰å–æœ‰ä»£è¡¨æ€§çš„10ä¸ªï¼‰
# ============================================================================
TEST_QUERIES = [
    # Aç±»ï¼šæ•°å€¼å±æ€§ (3ä¸ª)
    {"id": "A01", "query": "æ¨å®¶æ¨ªæ°´åº“çš„æ±›é™æ°´ä½æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§", 
     "keywords": ["æ±›é™æ°´ä½", "298", "æ°´ä½"]},
    {"id": "A03", "query": "æ¨å®¶æ¨ªæ°´åº“çš„æ ¡æ ¸æ´ªæ°´ä½æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "keywords": ["æ ¡æ ¸", "æ´ªæ°´ä½", "304"]},
    {"id": "A07", "query": "æ¨å®¶æ¨ªæ°´åº“æ§åˆ¶çš„æµåŸŸé¢ç§¯æ˜¯å¤šå°‘ï¼Ÿ", "category": "A-æ•°å€¼å±æ€§",
     "keywords": ["æµåŸŸé¢ç§¯", "å¹³æ–¹å…¬é‡Œ", "km"]},
    
    # Bç±»ï¼šå®ä½“å…³ç³» (4ä¸ª)
    {"id": "B01", "query": "æ¨å®¶æ¨ªæ°´åº“çš„å¤§åå®‰å…¨è´£ä»»äººæ˜¯è°ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "keywords": ["è´£ä»»äºº", "å®‰å…¨", "è´Ÿè´£"]},
    {"id": "B03", "query": "æ¨å®¶æ¨ªæ°´åº“ç”±å“ªä¸ªå•ä½ç®¡ç†ï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "keywords": ["ç®¡ç†", "å•ä½", "å¤„"]},
    {"id": "B05", "query": "æ¨å®¶æ¨ªæ°´åº“ä½äºå“ªæ¡æ²³æµä¸Šï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "keywords": ["æ²³æµ", "ä½äº", "æ²³"]},
    {"id": "B06", "query": "å¸¸åº„æ°´åº“ä¸‹æ¸¸ä¸»è¦ä¿æŠ¤å“ªäº›åŒºåŸŸï¼Ÿ", "category": "B-å®ä½“å…³ç³»",
     "keywords": ["ä¸‹æ¸¸", "ä¿æŠ¤", "åŒºåŸŸ"]},
    
    # Cç±»ï¼šæµç¨‹æ¡ä»¶ (3ä¸ª)
    {"id": "C01", "query": "ä»€ä¹ˆæƒ…å†µä¸‹éœ€è¦å¯åŠ¨IIIçº§åº”æ€¥å“åº”ï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "keywords": ["IIIçº§", "å“åº”", "å¯åŠ¨"]},
    {"id": "C03", "query": "é˜²æ´ªæŠ¢é™©ç‰©èµ„å‚¨å¤‡åŒ…æ‹¬å“ªäº›ä¸œè¥¿ï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "keywords": ["ç‰©èµ„", "å‚¨å¤‡", "åŒ…æ‹¬"]},
    {"id": "C05", "query": "å ¤é˜²å·¡æŸ¥çš„å…·ä½“æ­¥éª¤æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "C-æµç¨‹æ¡ä»¶",
     "keywords": ["å·¡æŸ¥", "æ­¥éª¤", "æ£€æŸ¥"]},
]

# ============================================================================
# æ•°æ®åº“è·¯å¾„
# ============================================================================
BASE_DIR = Path(__file__).parents[1]
DB_DIR = BASE_DIR / "src" / "db"

BASELINE_VECTOR_PATH = str(DB_DIR / "flood_prevention_db_baseline_vectordb")
BASELINE_BM25_PATH = str(DB_DIR / "flood_prevention_db_baseline_bm25")
CR_VECTOR_PATH = str(DB_DIR / "flood_prevention_db_cr_vectordb")
CR_BM25_PATH = str(DB_DIR / "flood_prevention_db_cr_bm25")

COLLECTION_NAME = "flood_prevention_collection"


class HybridRetriever(BaseRetriever):
    """æ··åˆæ£€ç´¢å™¨ï¼ˆå‘é‡+BM25ï¼‰ï¼Œè¿”å›åŸå§‹ nodes ç”¨äºåˆ†æ"""
    def __init__(self, vector_retriever, bm25_retriever, top_k=10):
        self.vector_retriever = vector_retriever
        self.bm25_retriever = bm25_retriever
        self.top_k = top_k
        super().__init__()

    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
        vector_results = self.vector_retriever.retrieve(query_bundle) if self.vector_retriever else []
        bm25_results = self.bm25_retriever.retrieve(query_bundle) if self.bm25_retriever else []
        
        all_nodes = {}
        for node in vector_results + bm25_results:
            if node.node_id not in all_nodes:
                all_nodes[node.node_id] = node
            else:
                if node.score and node.score > all_nodes[node.node_id].score:
                    all_nodes[node.node_id] = node
        
        sorted_nodes = sorted(all_nodes.values(), key=lambda x: x.score if x.score else 0, reverse=True)
        return sorted_nodes[:self.top_k]


def init_retriever(vector_db_path, bm25_path, collection_name, name=""):
    """åˆå§‹åŒ–æ£€ç´¢å™¨"""
    print(f"ğŸ”¹ {name}: åŠ è½½æ•°æ®åº“...")
    
    embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-zh-v1.5", device="cpu")
    
    if not os.path.exists(vector_db_path):
        print(f"   âŒ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨: {vector_db_path}")
        return None
    
    db = chromadb.PersistentClient(path=vector_db_path)
    try:
        chroma_collection = db.get_collection(collection_name)
        print(f"   âœ“ å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ (æ–‡æ¡£æ•°: {chroma_collection.count()})")
    except Exception as e:
        print(f"   âŒ åŠ è½½Collectionå¤±è´¥: {e}")
        return None
    
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    vector_index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)
    vector_retriever = vector_index.as_retriever(similarity_top_k=VECTOR_TOP_K)
    
    bm25_retriever = None
    if os.path.exists(bm25_path):
        try:
            bm25_retriever = BM25Retriever.from_persist_dir(bm25_path)
            bm25_retriever._similarity_top_k = BM25_TOP_K
            print(f"   âœ“ BM25ç´¢å¼•åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"   âš ï¸ BM25åŠ è½½å¤±è´¥: {e}")
    
    return HybridRetriever(vector_retriever, bm25_retriever, top_k=VECTOR_TOP_K + BM25_TOP_K)


def evaluate_keywords(text, keywords):
    """å…³é”®è¯å‘½ä¸­è¯„ä¼°"""
    hits = [kw for kw in keywords if kw in text]
    return len(hits) / len(keywords), hits


def run_case_analysis():
    """è¿è¡Œ Case çº§åˆ«åˆ†æ"""
    print("=" * 80)
    print("Phase 3 éªŒè¯å®éªŒï¼šCase çº§åˆ«åˆ†æ")
    print("=" * 80)
    print(f"\nğŸ• å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ éªŒè¯é—®é¢˜æ•°: {len(TEST_QUERIES)}")
    print(f"âš™ï¸ é…ç½®: VECTOR_TOP_K={VECTOR_TOP_K}, BM25_TOP_K={BM25_TOP_K}, FINAL_TOP_K={FINAL_TOP_K}")
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 1: åˆå§‹åŒ–æ£€ç´¢å™¨")
    print("=" * 80)
    
    baseline_retriever = init_retriever(
        BASELINE_VECTOR_PATH, BASELINE_BM25_PATH, COLLECTION_NAME, "Baseline"
    )
    cr_retriever = init_retriever(
        CR_VECTOR_PATH, CR_BM25_PATH, COLLECTION_NAME, "CR Enhanced"
    )
    
    if not baseline_retriever or not cr_retriever:
        print("âŒ æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º")
        return
    
    # Case çº§åˆ«åˆ†æ
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 2: Case çº§åˆ«å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    
    case_results = []
    
    for item in TEST_QUERIES:
        qid = item["id"]
        query = item["query"]
        category = item["category"]
        keywords = item["keywords"]
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Œ [{qid}] {query}")
        print(f"   ç±»åˆ«: {category} | å…³é”®è¯: {keywords}")
        print(f"{'='*80}")
        
        # Baseline æ£€ç´¢
        baseline_nodes = baseline_retriever.retrieve(query)[:FINAL_TOP_K]
        
        # CR æ£€ç´¢
        cr_nodes = cr_retriever.retrieve(query)[:FINAL_TOP_K]
        
        # åˆ†æ Baseline
        print(f"\nğŸ”µ Baseline æ£€ç´¢ç»“æœ (top-{FINAL_TOP_K}):")
        baseline_all_text = ""
        for i, node in enumerate(baseline_nodes):
            text = node.node.get_content()
            baseline_all_text += text + " "
            score = node.score if node.score else 0
            # æˆªå–å‰200å­—ç¬¦
            preview = text[:200].replace('\n', ' ')
            print(f"   [{i+1}] score={score:.4f}")
            print(f"       {preview}...")
        
        baseline_hit_rate, baseline_hits = evaluate_keywords(baseline_all_text, keywords)
        print(f"   ğŸ“Š å…³é”®è¯å‘½ä¸­: {baseline_hits} ({baseline_hit_rate*100:.0f}%)")
        
        # åˆ†æ CR
        print(f"\nğŸŸ¢ CR Enhanced æ£€ç´¢ç»“æœ (top-{FINAL_TOP_K}):")
        cr_all_text = ""
        for i, node in enumerate(cr_nodes):
            text = node.node.get_content()
            cr_all_text += text + " "
            score = node.score if node.score else 0
            # æˆªå–å‰200å­—ç¬¦
            preview = text[:200].replace('\n', ' ')
            print(f"   [{i+1}] score={score:.4f}")
            print(f"       {preview}...")
        
        cr_hit_rate, cr_hits = evaluate_keywords(cr_all_text, keywords)
        print(f"   ğŸ“Š å…³é”®è¯å‘½ä¸­: {cr_hits} ({cr_hit_rate*100:.0f}%)")
        
        # å¯¹æ¯”åˆ†æ
        print(f"\nğŸ“ˆ å¯¹æ¯”:")
        if cr_hit_rate > baseline_hit_rate:
            winner = "CR âœ…"
        elif cr_hit_rate < baseline_hit_rate:
            winner = "Baseline âœ…"
        else:
            winner = "å¹³å±€"
        print(f"   Baseline: {baseline_hit_rate*100:.0f}% vs CR: {cr_hit_rate*100:.0f}% â†’ {winner}")
        
        # æ£€æŸ¥æ˜¯å¦æ£€ç´¢åˆ°ç›¸åŒçš„æ–‡æ¡£
        baseline_ids = set(n.node_id for n in baseline_nodes)
        cr_ids = set(n.node_id for n in cr_nodes)
        overlap = baseline_ids.intersection(cr_ids)
        print(f"   æ–‡æ¡£é‡å : {len(overlap)}/{FINAL_TOP_K} ({len(overlap)/FINAL_TOP_K*100:.0f}%)")
        
        case_results.append({
            "id": qid,
            "query": query,
            "category": category,
            "baseline_score": baseline_nodes[0].score if baseline_nodes else 0,
            "cr_score": cr_nodes[0].score if cr_nodes else 0,
            "baseline_hit_rate": baseline_hit_rate,
            "cr_hit_rate": cr_hit_rate,
            "baseline_correct": baseline_hit_rate >= 0.5,
            "cr_correct": cr_hit_rate >= 0.5,
            "winner": winner,
            "doc_overlap": len(overlap) / FINAL_TOP_K
        })
    
    # ============================================================================
    # æ±‡æ€»ç»Ÿè®¡
    # ============================================================================
    print("\n" + "=" * 80)
    print("æ­¥éª¤ 3: æ±‡æ€»ç»Ÿè®¡")
    print("=" * 80)
    
    baseline_correct = sum(1 for r in case_results if r["baseline_correct"])
    cr_correct = sum(1 for r in case_results if r["cr_correct"])
    baseline_wins = sum(1 for r in case_results if "Baseline" in r["winner"])
    cr_wins = sum(1 for r in case_results if "CR" in r["winner"])
    ties = sum(1 for r in case_results if "å¹³å±€" in r["winner"])
    
    avg_baseline_score = np.mean([r["baseline_score"] for r in case_results])
    avg_cr_score = np.mean([r["cr_score"] for r in case_results])
    avg_overlap = np.mean([r["doc_overlap"] for r in case_results])
    
    print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      éªŒè¯å®éªŒæ±‡æ€»                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  é…ç½®: VECTOR_TOP_K={VECTOR_TOP_K}, BM25_TOP_K={BM25_TOP_K}, FINAL_TOP_K={FINAL_TOP_K}
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        æ£€ç´¢æ­£ç¡®ç‡                              â”‚
â”‚  Baseline: {baseline_correct}/{len(case_results)} ({baseline_correct/len(case_results)*100:.1f}%)                                      
â”‚  CR:       {cr_correct}/{len(case_results)} ({cr_correct/len(case_results)*100:.1f}%)                                      
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        èƒœè´Ÿç»Ÿè®¡                                â”‚
â”‚  Baseline èƒœ: {baseline_wins}                                              
â”‚  CR èƒœ:       {cr_wins}                                              
â”‚  å¹³å±€:        {ties}                                              
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        å¹³å‡åˆ†æ•°                                â”‚
â”‚  Baseline: {avg_baseline_score:.4f}                                        
â”‚  CR:       {avg_cr_score:.4f}                                        
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        æ–‡æ¡£é‡å ç‡                              â”‚
â”‚  å¹³å‡: {avg_overlap*100:.1f}%                                              
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
    
    # åˆ†ç±»ç»Ÿè®¡
    print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
    for cat in ["A-æ•°å€¼å±æ€§", "B-å®ä½“å…³ç³»", "C-æµç¨‹æ¡ä»¶"]:
        cat_results = [r for r in case_results if r["category"] == cat]
        cat_baseline = sum(1 for r in cat_results if r["baseline_correct"])
        cat_cr = sum(1 for r in cat_results if r["cr_correct"])
        print(f"   {cat}: Baseline {cat_baseline}/{len(cat_results)}, CR {cat_cr}/{len(cat_results)}")
    
    # ä¿å­˜ç»“æœ
    results_dir = BASE_DIR / "results"
    results_dir.mkdir(exist_ok=True)
    
    output_path = results_dir / "phase3_case_analysis.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "config": {
                "vector_top_k": VECTOR_TOP_K,
                "bm25_top_k": BM25_TOP_K,
                "final_top_k": FINAL_TOP_K
            },
            "summary": {
                "baseline_accuracy": baseline_correct / len(case_results),
                "cr_accuracy": cr_correct / len(case_results),
                "baseline_wins": baseline_wins,
                "cr_wins": cr_wins,
                "ties": ties,
                "avg_doc_overlap": avg_overlap
            },
            "cases": case_results
        }, f, ensure_ascii=False, indent=2)
    print(f"\nâœ“ ç»“æœå·²ä¿å­˜: {output_path}")
    
    # ============================================================================
    # å…³é”®å‘ç°
    # ============================================================================
    print("\n" + "=" * 80)
    print("ğŸ” å…³é”®å‘ç°")
    print("=" * 80)
    
    if avg_overlap > 0.7:
        print("âš ï¸ Baseline å’Œ CR æ£€ç´¢åˆ°çš„æ–‡æ¡£é«˜åº¦é‡å ï¼Œè¯´æ˜ CR ä¸Šä¸‹æ–‡å¯èƒ½æœªæ˜¾è‘—æ”¹å˜æ£€ç´¢ç»“æœ")
    
    if baseline_correct > cr_correct:
        print("âš ï¸ Baseline æ­£ç¡®ç‡ > CR æ­£ç¡®ç‡ï¼Œå¯èƒ½åŸå› ï¼š")
        print("   1. CR ä¸Šä¸‹æ–‡å¼•å…¥äº†å™ªéŸ³")
        print("   2. å…³é”®è¯è¯„ä¼°æŒ‡æ ‡æœ¬èº«æœ‰åå·®")
        print("   3. æ•°æ®ç‰¹æ€§ä¸é€‚åˆ CR")
    
    if avg_baseline_score < 0.6:
        print("âš ï¸ æ£€ç´¢åˆ†æ•°æ™®éè¾ƒä½ï¼Œå¯èƒ½è¯´æ˜ï¼š")
        print("   1. é—®é¢˜ä¸æ–‡æ¡£åŒ¹é…åº¦ä¸é«˜")
        print("   2. Embedding æ¨¡å‹å¯¹æ°´åˆ©é¢†åŸŸæœ¯è¯­ä¸æ•æ„Ÿ")
    
    return case_results


if __name__ == "__main__":
    run_case_analysis()
