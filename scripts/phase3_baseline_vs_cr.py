"""
Phase 3: Baseline vs CR åŒç»„å¯¹æ¯”å®éªŒ
ä¸“æ³¨äºéªŒè¯ Contextual Retrieval (ä¸Šä¸‹æ–‡å¢å¼º) çš„æ•ˆæœæå‡
"""
import os
import sys
import json
import time
from pathlib import Path

if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from dotenv import load_dotenv
sys.path.insert(0, str(Path(__file__).parents[1]))

from llama_index.core import (
    VectorStoreIndex, 
    Settings,
    QueryBundle
)
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.retrievers.bm25 import BM25Retriever
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.schema import NodeWithScore
import chromadb
import jieba
from typing import List

load_dotenv()

# æµ‹è¯•é—®é¢˜é›† - é’ˆå¯¹ Baseline vs CR å¯¹æ¯”ä¼˜åŒ–
TEST_QUERIES = [
    # 1. æ•°å€¼å±æ€§ç±» - éœ€è¦ä¸Šä¸‹æ–‡æ‰èƒ½ç†è§£"æœ¬æ°´åº“"æŒ‡çš„æ˜¯å“ªä¸ª
    {"query": "æ¨å®¶æ¨ªæ°´åº“çš„æ±›é™æ°´ä½æ˜¯å¤šå°‘ï¼Ÿ", "category": "æ•°å€¼å±æ€§", "expected_context": "æ¨å®¶æ¨ªæ°´åº“"},
    {"query": "å¸¸åº„æ°´åº“çš„æ€»åº“å®¹æ˜¯å¤šå°‘ï¼Ÿ", "category": "æ•°å€¼å±æ€§", "expected_context": "å¸¸åº„æ°´åº“"},
    
    # 2. è´£ä»»äººç±» - CR åº”è¯¥èƒ½æ›´å¥½åœ°å…³è”è´£ä»»äººä¸å…·ä½“æ°´åº“
    {"query": "æ¨å®¶æ¨ªæ°´åº“çš„å¤§åå®‰å…¨è´£ä»»äººæ˜¯è°ï¼Ÿ", "category": "å®ä½“å…³ç³»", "expected_context": "æ¨å®¶æ¨ªæ°´åº“"},
    {"query": "å¸¸åº„æ°´åº“é˜²æ±›æŒ‡æŒ¥éƒ¨çš„æŒ‡æŒ¥é•¿æ˜¯è°ï¼Ÿ", "category": "å®ä½“å…³ç³»", "expected_context": "å¸¸åº„æ°´åº“"},

    # 3. æ¡ä»¶è§¦å‘ç±» - éœ€è¦ç†è§£"å¯åŠ¨æ¡ä»¶"çš„ä¸Šä¸‹æ–‡
    {"query": "ä»€ä¹ˆæƒ…å†µä¸‹éœ€è¦å¯åŠ¨IIIçº§åº”æ€¥å“åº”ï¼Ÿ", "category": "é€»è¾‘æ¡ä»¶", "expected_context": "åº”æ€¥å“åº”"},
    {"query": "æ°´åº“æ°´ä½è¾¾åˆ°å¤šå°‘æ—¶éœ€è¦å¼€å§‹æ³„æ´ªï¼Ÿ", "category": "é€»è¾‘æ¡ä»¶", "expected_context": "æ³„æ´ªæ¡ä»¶"},

    # 4. åˆ—è¡¨æšä¸¾ç±» - æ£€ç´¢å®Œæ•´æ€§æµ‹è¯•
    {"query": "é˜²æ´ªæŠ¢é™©ç‰©èµ„å‚¨å¤‡åŒ…æ‹¬å“ªäº›ä¸œè¥¿ï¼Ÿ", "category": "æ¸…å•æšä¸¾", "expected_context": "ç‰©èµ„å‚¨å¤‡"},
    {"query": "é˜²æ±›æŠ¢é™©é˜Ÿä¼ç”±å“ªäº›éƒ¨é—¨ç»„æˆï¼Ÿ", "category": "æ¸…å•æšä¸¾", "expected_context": "æŠ¢é™©é˜Ÿä¼"},
    
    # 5. æµç¨‹æè¿°ç±» - éœ€è¦å®Œæ•´ä¸Šä¸‹æ–‡
    {"query": "å ¤é˜²å·¡æŸ¥çš„å…·ä½“æ­¥éª¤æ˜¯ä»€ä¹ˆï¼Ÿ", "category": "æµç¨‹æè¿°", "expected_context": "å·¡æŸ¥æ­¥éª¤"},
    {"query": "å‘ç°é™©æƒ…ååº”è¯¥å¦‚ä½•æŠ¥å‘Šï¼Ÿ", "category": "æµç¨‹æè¿°", "expected_context": "é™©æƒ…æŠ¥å‘Š"},
]

def chinese_tokenizer(text):
    """ä¸­æ–‡åˆ†è¯å™¨"""
    return list(jieba.cut_for_search(text))

class HybridRetriever(BaseRetriever):
    """æ··åˆæ£€ç´¢å™¨ï¼ˆå‘é‡+BM25ï¼‰"""
    def __init__(self, vector_retriever, bm25_retriever):
        self.vector_retriever = vector_retriever
        self.bm25_retriever = bm25_retriever
        super().__init__()

    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
        vector_results = self.vector_retriever.retrieve(query_bundle) if self.vector_retriever else []
        bm25_results = self.bm25_retriever.retrieve(query_bundle) if self.bm25_retriever else []
        
        all_nodes = {}
        for node in vector_results + bm25_results:
            if node.node_id not in all_nodes:
                all_nodes[node.node_id] = node
            else:
                # åˆå¹¶åˆ†æ•°ï¼ˆå–æœ€é«˜åˆ†ï¼‰
                if node.score and node.score > all_nodes[node.node_id].score:
                    all_nodes[node.node_id] = node
        
        sorted_nodes = sorted(all_nodes.values(), key=lambda x: x.score if x.score else 0, reverse=True)
        return sorted_nodes[:10]

def init_retriever(vector_db_path, bm25_path, collection_name, name=""):
    """åˆå§‹åŒ–æ£€ç´¢å™¨"""
    print(f"ğŸ”¹ {name}: åŠ è½½æ•°æ®åº“...")
    
    embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-zh-v1.5", device="cpu")
    
    if not os.path.exists(vector_db_path):
        print(f"   âŒ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨: {vector_db_path}")
        return None
    
    db = chromadb.PersistentClient(path=vector_db_path)
    try:
        chroma_collection = db.get_collection(collection_name)
        print(f"   âœ“ å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ (æ–‡æ¡£æ•°: {chroma_collection.count()})")
    except Exception as e:
        print(f"   âŒ åŠ è½½Collectionå¤±è´¥: {e}")
        return None
    
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    vector_index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)
    vector_retriever = vector_index.as_retriever(similarity_top_k=5)
    
    bm25_retriever = None
    if os.path.exists(bm25_path):
        try:
            bm25_retriever = BM25Retriever.from_persist_dir(bm25_path)
            bm25_retriever._similarity_top_k = 5
            print(f"   âœ“ BM25ç´¢å¼•åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"   âš ï¸ BM25åŠ è½½å¤±è´¥: {e}")
    
    return HybridRetriever(vector_retriever, bm25_retriever)

def run_experiment(name, retriever, queries):
    """è¿è¡Œå•ç»„å®éªŒ"""
    print(f"\n{'='*70}")
    print(f"å®éªŒ: {name}")
    print(f"{'='*70}\n")
    
    if not retriever:
        print(f"âŒ {name} æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥")
        return None
    
    results = []
    for item in queries:
        query = item["query"]
        print(f"ğŸ” {query}")
        
        try:
            start = time.time()
            nodes = retriever.retrieve(QueryBundle(query))
            elapsed = time.time() - start
            
            if nodes and len(nodes) > 0:
                top_text = nodes[0].text[:200].replace('\n', ' ')
                top_score = nodes[0].score if nodes[0].score else 0
                results_count = len(nodes)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸä¸Šä¸‹æ–‡
                has_context = item.get("expected_context", "") in nodes[0].text
            else:
                top_text = "æ— ç»“æœ"
                top_score = 0
                results_count = 0
                has_context = False
            
            result = {
                "query": query,
                "category": item["category"],
                "time": elapsed,
                "top_1_text": top_text,
                "top_1_score": top_score,
                "results_count": results_count,
                "has_expected_context": has_context
            }
            results.append(result)
            
            context_mark = "âœ“" if has_context else "âœ—"
            print(f"   â±ï¸  è€—æ—¶: {elapsed:.2f}s | å¾—åˆ†: {top_score:.3f} | ä¸Šä¸‹æ–‡: {context_mark}")
            print(f"   ğŸ“„ {top_text[:100]}...\n")
            
        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}\n")
            results.append({
                "query": query,
                "category": item["category"],
                "error": str(e)
            })
    
    return results

def generate_report(baseline_results, cr_results, queries):
    """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    report_path = Path("results/phase3_baseline_vs_cr.md")
    report_path.parent.mkdir(exist_ok=True)
    
    md = "# Phase 3: Baseline vs CR å¯¹æ¯”å®éªŒæŠ¥å‘Š\n\n"
    md += f"**æµ‹è¯•æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    
    md += "## å®éªŒé…ç½®\n\n"
    md += "| å®éªŒç»„ | è¯´æ˜ |\n"
    md += "|--------|------|\n"
    md += "| **Baseline** | åŸå§‹æ–‡æ¡£åˆ†å—ç›´æ¥æ£€ç´¢ï¼ˆå‘é‡+BM25æ··åˆï¼‰ |\n"
    md += "| **CR Enhanced** | ä¸Šä¸‹æ–‡å¢å¼ºæ£€ç´¢ï¼ˆæ¯ä¸ªåˆ†å—å¢åŠ äº†LLMç”Ÿæˆçš„ä¸Šä¸‹æ–‡æ‘˜è¦ï¼‰ |\n\n"
    
    md += "## é€é¢˜å¯¹æ¯”\n\n"
    
    for i, item in enumerate(queries):
        query = item["query"]
        category = item["category"]
        
        b_result = baseline_results[i] if baseline_results and i < len(baseline_results) else {}
        c_result = cr_results[i] if cr_results and i < len(cr_results) else {}
        
        md += f"### Q{i+1}: {query}\n"
        md += f"**ç±»åˆ«**: {category}\n\n"
        
        md += "| æŒ‡æ ‡ | Baseline | CR Enhanced |\n"
        md += "|------|----------|-------------|\n"
        
        b_score = b_result.get("top_1_score", 0)
        c_score = c_result.get("top_1_score", 0)
        score_diff = c_score - b_score
        score_indicator = "ğŸ“ˆ" if score_diff > 0.05 else ("ğŸ“‰" if score_diff < -0.05 else "â¡ï¸")
        
        md += f"| ç›¸ä¼¼åº¦å¾—åˆ† | {b_score:.3f} | {c_score:.3f} {score_indicator} |\n"
        md += f"| æ£€ç´¢è€—æ—¶ | {b_result.get('time', 0):.2f}s | {c_result.get('time', 0):.2f}s |\n"
        md += f"| åŒ…å«é¢„æœŸä¸Šä¸‹æ–‡ | {'âœ“' if b_result.get('has_expected_context') else 'âœ—'} | {'âœ“' if c_result.get('has_expected_context') else 'âœ—'} |\n"
        
        md += f"\n**Baseline Top-1**: {b_result.get('top_1_text', 'N/A')[:150]}...\n\n"
        md += f"**CR Top-1**: {c_result.get('top_1_text', 'N/A')[:150]}...\n\n"
        md += "---\n\n"
    
    # æ±‡æ€»ç»Ÿè®¡
    md += "## æ±‡æ€»ç»Ÿè®¡\n\n"
    md += "| æŒ‡æ ‡ | Baseline | CR Enhanced | å·®å¼‚ |\n"
    md += "|------|----------|-------------|------|\n"
    
    if baseline_results and cr_results:
        b_scores = [r.get("top_1_score", 0) for r in baseline_results if "error" not in r]
        c_scores = [r.get("top_1_score", 0) for r in cr_results if "error" not in r]
        b_times = [r.get("time", 0) for r in baseline_results if "error" not in r]
        c_times = [r.get("time", 0) for r in cr_results if "error" not in r]
        b_context = sum(1 for r in baseline_results if r.get("has_expected_context"))
        c_context = sum(1 for r in cr_results if r.get("has_expected_context"))
        
        avg_b_score = sum(b_scores) / len(b_scores) if b_scores else 0
        avg_c_score = sum(c_scores) / len(c_scores) if c_scores else 0
        avg_b_time = sum(b_times) / len(b_times) if b_times else 0
        avg_c_time = sum(c_times) / len(c_times) if c_times else 0
        
        md += f"| å¹³å‡ç›¸ä¼¼åº¦å¾—åˆ† | {avg_b_score:.3f} | {avg_c_score:.3f} | {avg_c_score - avg_b_score:+.3f} |\n"
        md += f"| å¹³å‡æ£€ç´¢è€—æ—¶ | {avg_b_time:.2f}s | {avg_c_time:.2f}s | {avg_c_time - avg_b_time:+.2f}s |\n"
        md += f"| ä¸Šä¸‹æ–‡å‘½ä¸­æ•° | {b_context}/{len(queries)} | {c_context}/{len(queries)} | {c_context - b_context:+d} |\n"
    
    md += "\n## ç»“è®º\n\n"
    if avg_c_score > avg_b_score:
        improvement = ((avg_c_score - avg_b_score) / avg_b_score * 100) if avg_b_score > 0 else 0
        md += f"**CR Enhanced ç›¸æ¯” Baseline å¹³å‡ç›¸ä¼¼åº¦æå‡äº† {improvement:.1f}%**\n\n"
    else:
        md += "**CR Enhanced ä¸ Baseline æ•ˆæœç›¸è¿‘æˆ–ç•¥æœ‰ä¸‹é™**\n\n"
    
    md += "### åˆ†æ\n\n"
    md += "1. **ä¸Šä¸‹æ–‡å¢å¼ºçš„ä¼˜åŠ¿**: CR åœ¨éœ€è¦ç†è§£æ–‡æ¡£æ¥æºçš„æŸ¥è¯¢ï¼ˆå¦‚\"æ¨å®¶æ¨ªæ°´åº“\"ã€\"å¸¸åº„æ°´åº“\"ï¼‰ä¸Šè¡¨ç°æ›´å¥½\n"
    md += "2. **é€Ÿåº¦å·®å¼‚**: ä¸¤è€…æ£€ç´¢é€Ÿåº¦ç›¸è¿‘ï¼Œå› ä¸ºä¸Šä¸‹æ–‡æ˜¯åœ¨ç´¢å¼•æ„å»ºæ—¶é¢„å¤„ç†çš„\n"
    md += "3. **é€‚ç”¨åœºæ™¯**: CR æ›´é€‚åˆéœ€è¦ç²¾ç¡®å®šä½ç‰¹å®šå®ä½“çš„æŸ¥è¯¢\n"
    
    report_path.write_text(md, encoding='utf-8')
    print(f"\nğŸ“Š å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # åŒæ—¶ä¿å­˜ JSON æ ¼å¼
    json_path = Path("results/phase3_baseline_vs_cr.json")
    json_data = {
        "timestamp": time.strftime('%Y-%m-%d %H:%M:%S'),
        "baseline": baseline_results,
        "cr_enhanced": cr_results
    }
    json_path.write_text(json.dumps(json_data, ensure_ascii=False, indent=2), encoding='utf-8')
    print(f"ğŸ“Š JSONæ•°æ®å·²ä¿å­˜: {json_path}")

def main():
    print("="*80)
    print("  Phase 3: Baseline vs CR åŒç»„å¯¹æ¯”å®éªŒ")
    print("="*80)
    
    # æ•°æ®åº“è·¯å¾„é…ç½®
    BASELINE_VECTOR_DB = "./src/db/flood_prevention_db_baseline_vectordb"
    BASELINE_BM25_DB = "./src/db/flood_prevention_db_baseline_bm25"
    CR_VECTOR_DB = "./src/db/flood_prevention_db_cr_vectordb"
    CR_BM25_DB = "./src/db/flood_prevention_db_cr_bm25"
    COLLECTION_NAME = "flood_prevention_collection"
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    print("\n[1/3] åˆå§‹åŒ–æ£€ç´¢å™¨...")
    baseline_retriever = init_retriever(BASELINE_VECTOR_DB, BASELINE_BM25_DB, COLLECTION_NAME, "Baseline")
    cr_retriever = init_retriever(CR_VECTOR_DB, CR_BM25_DB, COLLECTION_NAME, "CR Enhanced")
    
    # è¿è¡Œå®éªŒ
    print("\n[2/3] è¿è¡Œå¯¹æ¯”å®éªŒ...")
    baseline_results = run_experiment("Baseline", baseline_retriever, TEST_QUERIES)
    cr_results = run_experiment("CR Enhanced", cr_retriever, TEST_QUERIES)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n[3/3] ç”ŸæˆæŠ¥å‘Š...")
    if baseline_results and cr_results:
        generate_report(baseline_results, cr_results, TEST_QUERIES)
    
    print("\n" + "="*80)
    print("âœ… Phase 3 å®éªŒå®Œæˆï¼")
    print("="*80)

if __name__ == "__main__":
    main()
